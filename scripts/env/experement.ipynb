{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def func(x,y):\n",
    "    return sum(x**3+x*y*y + x**3*y+y**6)\n",
    "\n",
    "inputs = (torch.ones(3),torch.ones(3))\n",
    "\n",
    "print(torch.autograd.functional.hessian(func,inputs))\n",
    "\n",
    "def func2(x):\n",
    "    return sum(x**3)\n",
    "\n",
    "inputs = torch.ones(3)\n",
    "\n",
    "print(torch.autograd.functional.hessian(func2,inputs))\n",
    "inputs2 = inputs.clone().detach().requires_grad_(True)\n",
    "out = func2(inputs2)\n",
    "out.backward()\n",
    "print(inputs2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "def func2(x,y):\n",
    "    return (x**2)*y\n",
    "inputs = torch.ones(3)\n",
    "inputs2 = (torch.ones(3),torch.ones(3))\n",
    "out = torch.autograd.functional.jacobian(func,inputs) # []\n",
    "out2 = torch.autograd.functional.jacobian(func2,inputs2) # []\n",
    "print(out)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "def func(x):\n",
    "    return x**3\n",
    "\n",
    "def func2(x,y):\n",
    "    return (x**3)*y\n",
    "inputs = torch.ones(3,requires_grad=True)\n",
    "inputs2 = (torch.ones(3),torch.ones(3))\n",
    "\n",
    "out2 = torch.autograd.functional.jacobian(func2, inputs2) # []\n",
    "# second = torch.autograd.grad(out[0][0], inputs, create_graph=True)\n",
    "def second_derivative_of_vector_func(func, inputs, wrt=None):\n",
    "    # func - func that takes vector input and return vector\n",
    "    # inputs - vector input or cartage of vectors for func\n",
    "    # wrt - if inputs are cartage, that wrt needs to choose the derivative option [[xx,xy],[yx,yy]]\n",
    "    jacobian = torch.autograd.functional.jacobian(func, inputs, create_graph = True) # []\n",
    "    print(jacobian)\n",
    "    if wrt is not None:\n",
    "        jacobian = jacobian[wrt[0]]\n",
    "        last_shape = inputs[wrt[0]].shape[0]\n",
    "    else:\n",
    "        last_shape = inputs.shape[0]\n",
    "    second = torch.zeros((jacobian.shape[0], jacobian.shape[1], last_shape))\n",
    "    for x in range(jacobian.shape[0]):\n",
    "        for y in range(jacobian.shape[1]):\n",
    "            second[x,y] = torch.autograd.grad(jacobian[x,y], inputs, create_graph=True)[0]\n",
    "    return second\n",
    "out = second_derivative_of_vector_func(func,inputs)\n",
    "# out2 = second_derivative_of_vector_func(func2,inputs2,wrt=[0,0])\n",
    "# second1 = torch.autograd.grad(out[0][1], inputs, create_graph=True)\n",
    "# out.backward()\n",
    "# print(second)\n",
    "# print(second1)\n",
    "\n",
    "# print(inputs.grad)\n",
    "print(out)\n",
    "# print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.0000, 4.0000, 0.2000, 0.4000], requires_grad=True)\n",
      "tensor([ 0.7568, -0.6536], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.7568, -0.6536])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor([2,3,4,0.2,0.4])\n",
    "x.requires_grad_(True)\n",
    "R = 0.1\n",
    "Vr = 0.3\n",
    "dt= 0.5\n",
    "\n",
    "# 1 IIC [IICx,IICy,Vr*self.dt]\n",
    "print(x)\n",
    "print(torch.sin(x[2])*torch.Tensor([-1,0])+torch.cos(x[2])*torch.Tensor([0,1]))\n",
    "# aux\n",
    "print(torch.tensor([-torch.sin(x[2]),torch.cos(x[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.0000, 4.0000, 0.2000, 0.4000], requires_grad=True)\n",
      "tensor([[-0.4161, -0.9093,  0.0000],\n",
      "        [ 0.9093, -0.4161,  0.0000],\n",
      "        [ 0.0000,  0.0000,  1.0000]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor([2,3,4,0.2,0.4])\n",
    "x.requires_grad_(True)\n",
    "R = 0.1\n",
    "Vr = 0.3\n",
    "dt= 0.5\n",
    "\n",
    "# 2 IIC [IICx,IICy,Vr*self.dt]\n",
    "print(x)\n",
    "aux1 = torch.eye(3)\n",
    "aux1[2,2]=0\n",
    "aux2 = torch.zeros((3,3))\n",
    "aux2[1,0] = 1\n",
    "aux2[0,1] = -1\n",
    "aux3 = torch.zeros((3,3))\n",
    "aux3[2,2] = 1\n",
    "\n",
    "# theta = \n",
    "out = torch.cos(x[2]*dt)*aux1+torch.sin(x[2]*dt)*aux2+aux3\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4161, -0.9093,  0.0000],\n",
       "        [ 0.9093, -0.4161,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[torch.cos(x[2]*dt),-torch.sin(x[2]*dt),  0],\n",
    "                       [torch.sin(x[2]*dt), torch.cos(x[2]*dt),  0],\n",
    "                       [        0,                       0,      1]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.0000, 4.0000, 0.2000, 0.4000], requires_grad=True)\n",
      "tensor([2.0757, 2.9346, 0.1500], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-56916b1394e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# out = torch.cos(x[2]*dt)*aux1+torch.sin(x[2]*dt)*aux2+aux3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIIC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIIC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mVr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIIC\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mVr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# torch.tensor([IIC,Vr*self.dt]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor([2,3,4,0.2,0.4])\n",
    "x.requires_grad_(True)\n",
    "R = 0.1\n",
    "Vr = 0.3\n",
    "dt= 0.5\n",
    "\n",
    "print(x)\n",
    "aux1 = torch.eye(3)\n",
    "aux1[2,2]=0\n",
    "aux2 = torch.zeros((3,3))\n",
    "aux2[1,0] = 1\n",
    "aux2[0,1] = -1\n",
    "aux3 = torch.zeros((3,3))\n",
    "aux3[2,2] = 1\n",
    "IIC = x[:2]+R*(\n",
    "                torch.sin(x[2])*torch.Tensor([-1,0])+\n",
    "                torch.cos(x[2])*torch.Tensor([0,1]))\n",
    "\n",
    "# aux1            \n",
    "# 3 IIC [IICx,IICy,Vr*self.dt]\n",
    "# theta = \n",
    "# out = torch.cos(x[2]*dt)*aux1+torch.sin(x[2]*dt)*aux2+aux3\n",
    "print(IIC[0]*torch.Tensor([1,0,0])+IIC[1]*torch.Tensor([0,1,0])+Vr*dt*torch.Tensor([0,0,1]))\n",
    "print(IIC*torch.Tensor([1,1,0])+Vr*dt*torch.Tensor([0,0,1]))\n",
    "\n",
    "# torch.tensor([IIC,Vr*self.dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aux1 tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.]])\n",
      "aux2 tensor([[ 0., -1.,  0.],\n",
      "        [ 1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "aux3 tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "aux1 = torch.eye(3)\n",
    "aux1[2,2]=0\n",
    "print(\"aux1\",aux1)\n",
    "aux2 = torch.zeros((3,3))\n",
    "aux2[1,0] = 1\n",
    "aux2[0,1] = -1\n",
    "print(\"aux2\",aux2)\n",
    "aux3 = torch.zeros((3,3))\n",
    "aux3[2,2] = 1\n",
    "print(\"aux3\",aux3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e,r  1 3\n",
      "e,r  2 4\n"
     ]
    }
   ],
   "source": [
    "x = [1,2]\n",
    "y = [3,4]\n",
    "for (e,r) in  zip(x,y):\n",
    "    print(\"e,r \",e,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time is 12.1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"time is {12.124421:.3}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
